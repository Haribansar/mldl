{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haribansar/mldl/blob/main/llm_project1/first_llm_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHiVnP1yH6RS"
      },
      "source": [
        "***Beautifully connected the colab and github***\n",
        "\n",
        "Let's start the learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Commenting from local system*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***Below code is implemented using Ollama APIs not OpenAI***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
        "HEADERS = {\"Content-Type\": \"application/json\"}\n",
        "MODEL = \"llama3.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Tell me a joke on engineers\"}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "payload = {\n",
        "    \"model\": MODEL,\n",
        "    \"messages\": messages,\n",
        "    \"stream\": False\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Why did the engineer cross the road?\n",
            "\n",
            "To get to the otter side! (get it? like \"other\" but also referring to an otter, because engineers love puns)\n"
          ]
        }
      ],
      "source": [
        "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
        "print(response.json()['message']['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages1 = [\n",
        "    {\"role\": \"user\", \"content\": \"Tell me a joke on doctors\"}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Why did the doctor put a band-aid on the computer?\n",
            "\n",
            "It had a virus!\n"
          ]
        }
      ],
      "source": [
        "#Let's call the Ollama as a package instead of using HTTP call\n",
        "import ollama\n",
        "\n",
        "response = ollama.chat(model=MODEL, messages=messages1)\n",
        "#print(response['message']['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***Let's implement the same as above using OpenAI for Ollama***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages2 = [\n",
        "    {\"role\": \"user\", \"content\": \"Why people watch movies\"}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "ollama_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
        "\n",
        "#response = ollama_openai.chat.completions.create(\n",
        "#    model=MODEL,\n",
        "#    messages=messages2\n",
        "#)\n",
        "\n",
        "#print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Let's replicate the day1 using ollama*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [],
      "source": [
        "headers = {\n",
        " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
        "}\n",
        "\n",
        "class Website:\n",
        "    def __init__(self, url):\n",
        "        self.url = url\n",
        "        response = requests.get(url=url, headers=headers)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        self.title = soup.title.string if soup.title else \"No title found\"\n",
        "        for irr in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
        "            irr.decompose()\n",
        "        self.text = soup.body.getText(separator=\"\\n\", strip=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [],
      "source": [
        "har = Website(\"https://edwarddonner.com\")\n",
        "#print(har.title)\n",
        "#print(har.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_prompt = \"You are an assistant that analyzes the content of a website \\\n",
        "    and provides a short summary of this website in markdown. \\\n",
        "    Respond in Markdown.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [],
      "source": [
        "def user_prompt_for(website):\n",
        "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
        "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
        "please provide a short summary of this website in markdown. \\\n",
        "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
        "    user_prompt += website.text\n",
        "    return user_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [],
      "source": [
        "#print(user_prompt_for(har))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [],
      "source": [
        "def message_create(website):\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'role': 'system',\n",
              "  'content': 'You are an assistant that analyzes the content of a website     and provides a short summary of this website in markdown.         Respond in Markdown.'},\n",
              " {'role': 'user',\n",
              "  'content': 'You are looking at a website titled Home - Edward Donner\\nThe contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nWell, hi there.\\nI’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\\nvery\\namateur) and losing myself in\\nHacker News\\n, nodding my head sagely to things I only half understand.\\nI’m the co-founder and CTO of\\nNebula.io\\n. We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\\nacquired in 2021\\n.\\nWe work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\\npatented\\nour matching model, and our award-winning platform has happy customers and tons of press coverage.\\nConnect\\nwith me for more!\\nMay 28, 2025\\nConnecting my courses – become an LLM expert and leader\\nMay 18, 2025\\n2025 AI Executive Briefing\\nApril 21, 2025\\nThe Complete Agentic AI Engineering Course\\nJanuary 23, 2025\\nLLM Workshop – Hands-on with Agents – resources\\nNavigation\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nGet in touch\\ned [at] edwarddonner [dot] com\\nwww.edwarddonner.com\\nFollow me\\nLinkedIn\\nTwitter\\nFacebook\\nSubscribe to newsletter\\nType your email…\\nSubscribe'}]"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#message_create(har)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [],
      "source": [
        "def summarize(url):\n",
        "    website = Website(url)\n",
        "    #response = ollama_openai.chat.completions.create(\n",
        "    #    model = \"llama3.2\",\n",
        "    #    messages = message_create(website)\n",
        "    #)\n",
        "    #return response.choices[0].message.content\n",
        "    response = ollama.chat(MODEL, message_create(website))\n",
        "    return response['message']['content']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [],
      "source": [
        "#summarize(\"https://edwarddonner.com\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_summary(url):\n",
        "    summary = summarize(url)\n",
        "    display(Markdown(summary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "# Website Summary: Edward Donner's Home Page\n",
              "=============================================\n",
              "\n",
              "## Introduction\n",
              "-----------------\n",
              "\n",
              "The website is owned by Ed, the CTO and co-founder of Nebula.io. The page provides an overview of his interests and professional background.\n",
              "\n",
              "## About Ed\n",
              "-------------\n",
              "\n",
              "Ed enjoys writing code, experimenting with Large Language Models (LLMs), DJing, electronic music production, and reading Hacker News. He is the co-founder and CEO of AI startup Nebula.io, which applies AI to help people discover their potential.\n",
              "\n",
              "## Recent Announcements\n",
              "----------------------\n",
              "\n",
              "*   **2025 AI Executive Briefing**: An upcoming event that will discuss the latest trends in AI.\n",
              "*   **The Complete Agentic AI Engineering Course**: A new course on agentic AI engineering.\n",
              "*   **LLM Workshop – Hands-on with Agents**: Resources for an LLM workshop on agents.\n",
              "\n",
              "## Navigation and Contact Information\n",
              "--------------------------------------\n",
              "\n",
              "The website includes links to Ed's LinkedIn, Twitter, Facebook profiles, as well as a contact form for subscribers."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#display_summary(\"https://edwarddonner.com\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "# HL Klemove Official Website\n",
              "\n",
              "## Overview\n",
              "\n",
              "HL Klemove is a global company that specializes in autonomous driving solutions, automotive electronics, and data solutions. The company was formed by the merger of Mando's ADAS business unit and the transmission technology division.\n",
              "\n",
              "### Tagline\n",
              "\n",
              "\"Klemove: Leaping into the Wider World\"\n",
              "\n",
              "## Business Areas\n",
              "\n",
              "* Autonomous Driving Solutions\n",
              "\t+ Radar\n",
              "\t+ Camera\n",
              "\t+ LiDAR\n",
              "\t+ 3D Scanning LiDAR\n",
              "\t+ Autonomous Driving Integrated Controller\n",
              "* Automotive Electronics Solutions\n",
              "\t+ Engine Sound System (AVAS)\n",
              "\t+ Chassis ECU\n",
              "\t+ Vehicle Braking and Steering Systems\n",
              "\t+ Data Solutions\n",
              "\n",
              "## Sustainability\n",
              "\n",
              "HL Klemove prioritizes sustainability, with a focus on reducing environmental impact and promoting social responsibility.\n",
              "\n",
              "### Initiatives\n",
              "\n",
              "* Long-term business strategies to minimize ecological footprint\n",
              "* Respect for human rights and dignity\n",
              "* Philanthropic efforts to support local communities\n",
              "* Adherence to quality management standards\n",
              "\n",
              "## News and Announcements\n",
              "\n",
              "HL Klemove regularly publishes news and announcements on its website, including:\n",
              "\n",
              "* Vision statements\n",
              "* Press releases\n",
              "* Industry insights\n",
              "* Global updates"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#display_summary(\"https://hlklemove.com/main.do\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM6RVSdd5lM/eABbtxGx4xv",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "llms",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
