{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90e85a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a862959e",
   "metadata": {},
   "source": [
    "*Introduction of LangChain*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e7e80c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e8f21c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"llama3.2\"\n",
    "ollama_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7974ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob.glob(\"knowledge-base/*\")\n",
    "\n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    folder_docs = loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1479da0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5cecf660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'knowledge-base/products/Rellm.md', 'doc_type': 'products'}, page_content=\"# Product Summary\\n\\n# Rellm: AI-Powered Enterprise Reinsurance Solution\\n\\n## Summary\\n\\nRellm is an innovative enterprise reinsurance product developed by Insurellm, designed to transform the way reinsurance companies operate. Harnessing the power of artificial intelligence, Rellm offers an advanced platform that redefines risk management, enhances decision-making processes, and optimizes operational efficiencies within the reinsurance industry. With seamless integrations and robust analytics, Rellm enables insurers to proactively manage their portfolios and respond to market dynamics with agility.\\n\\n## Features\\n\\n### AI-Driven Analytics\\nRellm utilizes cutting-edge AI algorithms to provide predictive insights into risk exposures, enabling users to forecast trends and make informed decisions. Its real-time data analysis empowers reinsurance professionals with actionable intelligence.\\n\\n### Seamless Integrations\\nRellm's architecture is designed for effortless integration with existing systems. Whether it's policy management, claims processing, or financial reporting, Rellm connects seamlessly with diverse data sources to create a unified ecosystem.\\n\\n### Risk Assessment Module\\nThe comprehensive risk assessment module within Rellm allows insurers to evaluate risk profiles accurately. By leveraging historical data and advanced modeling techniques, Rellm provides a clear picture of potential liabilities and expected outcomes.\\n\\n### Customizable Dashboard\\nRellm features a customizable dashboard that presents key metrics and performance indicators in an intuitive interface. Users can tailor their view to focus on what matters most to their business, enhancing user experience and productivity.\\n\\n### Regulatory Compliance Tools\\nRellm includes built-in compliance tracking features to help organizations meet local and international regulatory standards. This ensures that reinsurance practices remain transparent and accountable.\\n\\n### Client and Broker Portals\\nRellm offers dedicated portals for both clients and brokers, facilitating real-time communication and documentation sharing. This strengthens partnerships and drives operational excellence across the board.\\n\\n## Pricing\\n\\nInsurellm offers flexible pricing plans for Rellm to cater to various business needs:\\n\\n- **Basic Plan**: $5,000/month\\n  - Includes access to core features and standard integrations.\\n  \\n- **Professional Plan**: $10,000/month\\n  - Includes all features, advanced integrations, and priority customer support.\\n  \\n- **Enterprise Plan**: Custom pricing\\n  - Tailored solutions with personalized features, extensive integrations, and dedicated account management.\\n\\nJoin the growing number of organizations leveraging Rellm to enhance their reinsurance processes while driving profitability and compliance. \\n\\n## 2025-2026 Roadmap\\n\\nAt Insurellm, we are committed to the continuous improvement of Rellm. Our roadmap for 2025-2026 includes:\\n\\n- **Q3 2025**: \\n  - Launch of the Rellm Mobile App for on-the-go insights and management.\\n  - Introduction of augmented reality (AR) features for interactive risk assessments.\\n\\n- **Q1 2026**: \\n  - Deployment of advanced machine learning models for even more accurate risk predictions.\\n  - Expansion of integration capabilities to support emerging technologies in the insurance sector.\\n\\n- **Q3 2026**: \\n  - Release of a community platform for Rellm users to exchange insights, tips, and best practices.\\n  - Launch of Rellm 2.0, featuring enhanced user interface and premium features based on user feedback.\\n\\nExperience the future of reinsurance with Rellm, where innovation meets reliability. Let Insurellm help you navigate the complexities of the reinsurance market smarter and faster.\")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd258618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1088, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a31cdb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "24f034d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'knowledge-base/employees/Samantha Greene.md', 'doc_type': 'employees'}, page_content=\"- **2023:** Base Salary - $70,000  \\n  Recognized for substantial improvement in employee relations management and contributions to company culture, leading to a well-deserved increase.\\n\\n## Other HR Notes\\n- Samantha Greene has expressed interest in pursuing an HR certification (SHRM-CP) to further her career growth within Insurellm. \\n- Participated in Insurellm's employee wellness program, promoting mental health resources among staff.\\n- Actively volunteers with local nonprofits and encourages staff involvement in community outreach programs, enhancing Insurellm's corporate social responsibility initiatives. \\n\\nSamantha Greene is a valuable asset to Insurellm, continuously working on professional development and contributing to a supportive workplace culture.\")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "72d9af61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document types found: contracts, employees, products, company\n"
     ]
    }
   ],
   "source": [
    "doc_types = set(chunk.metadata['doc_type'] for chunk in chunks)\n",
    "print(f\"Document types found: {', '.join(doc_types)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "638c8732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='# Avery Lancaster\n",
      "\n",
      "## Summary\n",
      "- **Date of Birth**: March 15, 1985  \n",
      "- **Job Title**: Co-Founder & Chief Executive Officer (CEO)  \n",
      "- **Location**: San Francisco, California  \n",
      "\n",
      "## Insurellm Career Progression\n",
      "- **2015 - Present**: Co-Founder & CEO  \n",
      "  Avery Lancaster co-founded Insurellm in 2015 and has since guided the company to its current position as a leading Insurance Tech provider. Avery is known for her innovative leadership strategies and risk management expertise that have catapulted the company into the mainstream insurance market.  \n",
      "\n",
      "- **2013 - 2015**: Senior Product Manager at Innovate Insurance Solutions  \n",
      "  Before launching Insurellm, Avery was a leading Senior Product Manager at Innovate Insurance Solutions, where she developed groundbreaking insurance products aimed at the tech sector.' metadata={'source': 'knowledge-base/employees/Avery Lancaster.md', 'doc_type': 'employees'}\n",
      "_________\n",
      "page_content='3. **Regular Updates:** Insurellm will offer ongoing updates and enhancements to the Homellm platform, including new features and security improvements.\n",
      "\n",
      "4. **Feedback Implementation:** Insurellm will actively solicit feedback from GreenValley Insurance to ensure Homellm continues to meet their evolving needs.\n",
      "\n",
      "---\n",
      "\n",
      "**Signatures:**\n",
      "\n",
      "_________________________________  \n",
      "**[Name]**  \n",
      "**Title**: CEO  \n",
      "**Insurellm, Inc.**\n",
      "\n",
      "_________________________________  \n",
      "**[Name]**  \n",
      "**Title**: COO  \n",
      "**GreenValley Insurance, LLC**  \n",
      "\n",
      "---\n",
      "\n",
      "This agreement represents the complete understanding of both parties regarding the use of the Homellm product and supersedes any prior agreements or communications.' metadata={'source': 'knowledge-base/contracts/Contract with GreenValley Insurance for Homellm.md', 'doc_type': 'contracts'}\n",
      "_________\n",
      "page_content='## Support\n",
      "\n",
      "1. **Customer Support**: Velocity Auto Solutions will have access to Insurellm’s customer support team via email or chatbot, available 24/7.  \n",
      "2. **Technical Maintenance**: Regular maintenance and updates to the Carllm platform will be conducted by Insurellm, with any downtime communicated in advance.  \n",
      "3. **Training & Resources**: Initial training sessions will be provided for Velocity Auto Solutions’ staff to ensure effective use of the Carllm suite. Regular resources and documentation will be made available online.\n",
      "\n",
      "---\n",
      "\n",
      "**Accepted and Agreed:**  \n",
      "**For Velocity Auto Solutions**  \n",
      "Signature: _____________________  \n",
      "Name: John Doe  \n",
      "Title: CEO  \n",
      "Date: _____________________  \n",
      "\n",
      "**For Insurellm**  \n",
      "Signature: _____________________  \n",
      "Name: Jane Smith  \n",
      "Title: VP of Sales  \n",
      "Date: _____________________' metadata={'source': 'knowledge-base/contracts/Contract with Velocity Auto Solutions for Carllm.md', 'doc_type': 'contracts'}\n",
      "_________\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    if 'CEO' in chunk.page_content:\n",
    "        print(chunk)\n",
    "        print(\"_________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8600b306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
